{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn.model_selection import StratifiedKFold, validation_curve ,cross_val_score, cross_val_predict, RandomizedSearchCV, train_test_split\n",
    "import sklearn.feature_selection\n",
    "import catboost as ctb\n",
    "import lightgbm as lgb\n",
    "from sklearn.externals import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn.ensemble as ens\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, PassiveAggressiveClassifier, LogisticRegression\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerID = pd.read_csv('ID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.drop(columns=['Survived'])\n",
    "target = train.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Logistic Regression Model - Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to tune our model such that we minimize the variance, which is sensitivity of the prediction score to the change in training set, so, we will use cross-validation. We will use the validation curve to help us choose the best number of folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionCV(Cs=10, scoring='accuracy', max_iter=3000, refit=True)\n",
    "param_name = 'cv'\n",
    "param_range = list(range(3, 21))\n",
    "train_score, test_score = validation_curve(\n",
    "    lr, features, target, param_name, cv= None, param_range=param_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_score_mean = np.mean(train_score, axis= 1)\n",
    "test_score_mean = np.mean(test_score, axis= 1)\n",
    "\n",
    "# Plot number of folds VS. cross-validated scores for training and Validation sets.\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of folds\")\n",
    "plt.ylabel(\"Cross validated accuracy score\")\n",
    "plt.plot(np.arange(3,21), train_score_mean)\n",
    "plt.plot(np.arange(3,21), test_score_mean, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_test_diff = train_score_mean - test_score_mean\n",
    "\n",
    "# Plot number of folds VS. difference of cross-validated scores between train and Dev sets.\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of folds\")\n",
    "plt.ylabel(\"Diff. Cross validated accuracy score\")\n",
    "plt.plot(np.arange(3,21), train_test_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the minimum variance is obtained at K = 7 folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit our model and the use the best CV value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegressionCV(\n",
    "    Cs=10, cv= 7, scoring='accuracy', max_iter=3000, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the ROC curve for different threshold values.\n",
    "# probability estimates of the positive class.\n",
    "y_scores_lr = logistic_reg.predict_proba(features)[:, 1]\n",
    "lr_fpr, lr_tpr, lr_thresholds = sklearn.metrics.roc_curve(target, y_scores_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the AUC for the logistic classification model.\n",
    "lr_auc = sklearn.metrics.auc(x=lr_fpr, y=lr_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_acc = np.mean(logistic_reg.scores_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area Under Curve: {}, Accuracy: {}'.format(lr_auc, lr_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will try different method to select the features with the highest explainatory power. We will try the following methods, then we select the best method:\n",
    "1. VarianceThreshold\n",
    "2. SelectKBest\n",
    "3. RFECV\n",
    "4. SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.arange(1, 10, 0.5) *1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.VarianceThreshold(threshold= i)\n",
    "    selected_features = selector.fit_transform(features)\n",
    "    logistic_reg.fit(selected_features, target)\n",
    "    y_pred = logistic_reg.predict(selected_features)\n",
    "    scores.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "\n",
    "# Plot variance threshold VS. cross-validated scores for training sets.\n",
    "plt.figure()\n",
    "plt.xlabel(\"variance threshold\")\n",
    "plt.ylabel(\"Cross validated accuracy score\")\n",
    "plt.plot(np.arange(1, 10, 0.5) *1e-1, np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy is obtained after execluding features whose variance is less than 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKbest method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = list(range(1,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_k = []\n",
    "for i in number_of_features:\n",
    "    selector = sklearn.feature_selection.SelectKBest(k=i)\n",
    "    selected_features = selector.fit_transform(features, target)\n",
    "    logistic_reg.fit(selected_features, target)\n",
    "    y_pred = logistic_reg.predict(selected_features)\n",
    "    scores_k.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "\n",
    "# Plot number of selected features VS. cross-validated scores for training sets.\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of Selected Features\")\n",
    "plt.ylabel(\"Cross validated accuracy score\")    \n",
    "plt.plot(list(range(1,17)), scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum accuracy score is :\", max(scores_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features :\", np.argmax(np.array(scores_k)) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy score is obtained after selecting the best 14 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFECV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = sklearn.feature_selection.RFECV(logistic_reg, step= 1, cv= 5)\n",
    "selector.fit(features, target)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % selector.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum accuracy score is :\", np.max(selector.grid_scores_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFromModel method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.arange(1, 5, 0.1) *1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_sfm = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.SelectFromModel(logistic_reg, threshold= i)\n",
    "    selector.fit(features, target)\n",
    "    selected_features = features.loc[:, selector.get_support()]\n",
    "    logistic_reg.fit(selected_features, target)\n",
    "    y_pred = logistic_reg.predict(selected_features)\n",
    "    scores_sfm.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Threshold Value\")\n",
    "plt.ylabel(\"Cross validation score\")    \n",
    "plt.plot(np.arange(1, 5, 0.1) *1e-1, scores_sfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum accuracy score is :\", np.max(np.array(scores_sfm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal threshold :\", threshold[np.argmax(np.array(scores_sfm))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude the best feature selection method is SelectFromModel with threshold = 0.28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = sklearn.feature_selection.SelectFromModel(logistic_reg, threshold= 0.25)\n",
    "selector.fit(features, target)\n",
    "selected_features = features.loc[:, selector.get_support()]\n",
    "logistic_reg.fit(selected_features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = pd.DataFrame(logistic_reg.predict(\n",
    "    test.loc[:, selector.get_support()]), columns=['Survived'], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = pd.concat([passengerID, y_pred_nb], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.to_csv('logistic.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_params = {'priors': [[0.7, 0.3], [0.6, 0.4],\n",
    "                        [0.5, 0.5], [0.4, 0.6], [0.3, 0.7]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb = GridSearchCV(nb, param_grid=nb_params,\n",
    "                     scoring='accuracy', cv=kf, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the ROC curve for different threshold values.\n",
    "# probability estimates of the positive class.\n",
    "y_scores_nb = gs_nb.predict_proba(features)[:, 1]\n",
    "nb_fpr, nb_tpr, nb_thresholds = roc_curve(target, y_scores_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the AUC for the naive bayes classification model.\n",
    "nb_auc = auc(x=nb_fpr, y=nb_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_acc = gs_nb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area Under Curve: {}, Accuracy: {}'.format(nb_auc, nb_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = pd.DataFrame(gs_nb.predict(\n",
    "    test.drop(columns=['PassengerId'])), columns=['Survived'], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = pd.concat([test.PassengerId, y_pred_nb], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to tune our model such that we minimize the variance, which is sensitivity of the prediction score to the change in training set, so, we will use cross-validation. We will use the validation curve to help us choose the best number of neighbours (K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "param_name = 'n_neighbors'\n",
    "param_range = list(range(3, 21))\n",
    "train_score, test_score = validation_curve(\n",
    "    knn, features, target, param_name, cv= 10, param_range=param_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_score_mean = np.mean(train_score, axis= 1)\n",
    "test_score_mean = np.mean(test_score, axis= 1)\n",
    "\n",
    "# Plot number of neighbours VS. cross-validated scores for training and Validation sets.\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of neighbours\")\n",
    "plt.ylabel(\"Cross validated accuracy score\")\n",
    "plt.plot(np.arange(3,21), train_score_mean, color = 'blue')\n",
    "plt.plot(np.arange(3,21), test_score_mean, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_test_diff = train_score_mean - test_score_mean\n",
    "\n",
    "# Plot number of folds VS. difference of cross-validated scores between train and Dev sets.\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of neighbours\")\n",
    "plt.ylabel(\"Diff. Cross validated accuracy score\")\n",
    "plt.plot(np.arange(3,21), train_test_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the minimum variance is obtained at number of neighbours K = 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will try different method to select the features with the highest explainatory power. We will try the following methods, then we select the best method:\n",
    "1. VarianceThreshold\n",
    "2. SelectKBest\n",
    "3. RFECV\n",
    "4. SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.001, 0.005, 0.01, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.VarianceThreshold(threshold= i)\n",
    "    selected_features = selector.fit_transform(features)\n",
    "    knn.fit(selected_features, target)\n",
    "    y_pred = knn.predict(selected_features)\n",
    "    scores.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "\n",
    "# Plot variance threshold VS. cross-validated scores for training sets.\n",
    "plt.figure()\n",
    "plt.xlabel(\"variance threshold\")\n",
    "plt.ylabel(\"Cross validated accuracy score\")\n",
    "plt.plot([0.001, 0.005, 0.01, 0.05, 0.1, 0.2], np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKbest method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = list(range(1,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_k = []\n",
    "for i in number_of_features:\n",
    "    selector = sklearn.feature_selection.SelectKBest(k=i)\n",
    "    selected_features = selector.fit_transform(features, target)\n",
    "    knn.fit(selected_features, target)\n",
    "    y_pred = knn.predict(selected_features)\n",
    "    scores_k.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "\n",
    "# Plot number of selected features VS. cross-validated scores for training sets.\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of Selected Features\")\n",
    "plt.ylabel(\"Cross validated accuracy score\")    \n",
    "plt.plot(list(range(1,13)), scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum accuracy score is :\", max(scores_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features :\", np.argmax(np.array(scores_k)) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that, the highest accuracy is obtained after execluding features whose variance is less than 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model with the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors= 14)\n",
    "selector = sklearn.feature_selection.VarianceThreshold(threshold= 0.05)\n",
    "selected_features = selector.fit_transform(features)\n",
    "knn.fit(selected_features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN hyperparamters tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use randomized search to tune the hyperparamters of KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'n_neighbors': [14] , 'weights': [\n",
    "    'uniform', 'distance'], 'leaf_size': [20, 30, 40, 50, 60], 'p': [1, 2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_knn = RandomizedSearchCV(knn, param_distributions= knn_params,\n",
    "                      scoring='accuracy', cv= 20, n_iter= 100, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rs_knn.fit(selected_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the ROC curve for different threshold values.\n",
    "# probability estimates of the positive class.\n",
    "y_scores_knn = rs_knn.predict_proba(selected_features)[:, 1]\n",
    "knn_fpr, knn_tpr, knn_thresholds = sklearn.metrics.roc_curve(target, y_scores_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the AUC for the naive bayes classification model.\n",
    "knn_auc = sklearn.metrics.auc(x=knn_fpr, y=knn_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_acc = rs_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area Under Curve: {}, Accuracy: {}'.format(knn_auc, knn_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = pd.DataFrame(rs_knn.predict(\n",
    "    test.loc[:, selector.get_support()]), columns=['Survived'], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = pd.concat([passengerID, y_pred_knn], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.to_csv('knn.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {'C': [0.1, 1, 10, 100, 500], 'kernel': ['rbf'], 'degree': [\n",
    "    1, 2, 3, 4], 'gamma': [0.05, 0.1, 1, 5], 'shrinking': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_svm = RandomizedSearchCV(svm, param_distributions=svm_params,\n",
    "                            scoring='accuracy', cv=kf, refit=True, n_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_svm.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rs_svm, 'svmmodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_svm = joblib.load('svmmodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the ROC curve for different threshold values.\n",
    "# probability estimates of the positive class.\n",
    "y_scores_svm = rs_svm.predict_proba(features)[:, 1]\n",
    "svm_fpr, svm_tpr, svm_thresholds = roc_curve(target, y_scores_svm)\n",
    "# Finding the AUC for the SVM classification model.\n",
    "svm_auc = auc(x=svm_fpr, y=svm_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_acc = rs_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area Under Curve: {}, Accuracy: {}'.format(svm_auc, svm_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = pd.DataFrame(rs_svm.predict(\n",
    "    test.drop(columns=['PassengerId'])), columns=['Survived'], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = pd.concat([test.PassengerId, y_pred_svm], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection for decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.001, 0.01,0.1,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.VarianceThreshold(threshold= i)\n",
    "    selected_features = selector.fit_transform(features)\n",
    "    dt.fit(selected_features, target)\n",
    "    y_pred = dt.predict(selected_features)\n",
    "    scores.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "plt.plot([0.001, 0.01,0.1,0.5], np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy is obtained after execluding features whose variance is less than 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKbest method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = list(range(1,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_k = []\n",
    "for i in number_of_features:\n",
    "    selector = sklearn.feature_selection.SelectKBest(k=i)\n",
    "    selected_features = selector.fit_transform(features, target)\n",
    "    dt.fit(selected_features, target)\n",
    "    y_pred = dt.predict(selected_features)\n",
    "    scores_k.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "plt.plot(list(range(1,17)), scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features :\", np.argmax(np.array(scores_k)) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy score is obtained after selecting the best 12 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFECV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = sklearn.feature_selection.RFECV(dt, step= 1, cv= 7)\n",
    "selector.fit(features, target)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % selector.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(selector.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude the VarianceThreshold and SelectKbest methods results in the same accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the SelectKbest method with K = 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = sklearn.feature_selection.SelectKBest(k= 12)\n",
    "selected_features = selector.fit_transform(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree hyperparamters tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use randomized search method and we will follow coarse-to-fine strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {'criterion': ['gini'], 'min_samples_split': [\n",
    "    14, 15,16], 'max_features': ['auto', 'log2', None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dt = RandomizedSearchCV(dt, param_distributions= dt_params,\n",
    "                     scoring='accuracy', cv= StratifiedKFold(7), refit=True, n_iter= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dt.fit(selected_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_dt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the max_depth of tree to minimize the variance. We'll use the validation curve to select the best value of max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(min_samples_split= 15, max_features= None)\n",
    "param_name = 'max_depth'\n",
    "param_range = list(range(1, 11))\n",
    "train_score, test_score = validation_curve(\n",
    "    dt, selected_features, target, param_name, cv= 7, param_range = param_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_score_mean = np.mean(train_score, axis= 1)\n",
    "test_score_mean = np.mean(test_score, axis= 1)\n",
    "plt.plot(np.arange(1,11), train_score_mean)\n",
    "plt.plot(np.arange(1,11), test_score_mean, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_test_diff = train_score_mean - test_score_mean\n",
    "plt.plot(np.arange(1,11), train_test_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graphs, we find that the minimum is at max_depth of 1 but the bias is high. So, we will choose max_depth of 4 because the variance is reasonable and the bias is much lower than that of max_depth = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(min_samples_split= 15, max_features= None, max_depth= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(selected_features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the ROC curve for different threshold values.\n",
    "# probability estimates of the positive class.\n",
    "y_scores_dt = dt.predict_proba(selected_features)[:, 1]\n",
    "dt_fpr, dt_tpr, dt_thresholds = sklearn.metrics.roc_curve(target, y_scores_dt)\n",
    "# Finding the AUC for the Decision Tree classification model.\n",
    "dt_auc = sklearn.metrics.auc(x=dt_fpr, y=dt_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_acc = gs_dt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area Under Curve: {}, Accuracy: {}'.format(dt_auc, dt_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = pd.DataFrame(dt.predict(\n",
    "    test.loc[:,selector.get_support()]), columns=['Survived'], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = pd.concat([passengerID, y_pred_dt], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.to_csv('dt.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {'n_estimators': [10, 100, 200], 'criterion': ['gini', 'entropy'], 'min_samples_split': [\n",
    "    2, 5, 10], 'max_features': ['sqrt', 'log2', None], 'class_weight': [{0: 0.6, 1: 0.4}, {0: 0.6, 1: 0.4}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf = RandomizedSearchCV(rf, param_distributions=rf_params,\n",
    "                           scoring='accuracy', cv=kf, refit=True, n_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rs_rf, 'randomdorestmodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf = joblib.load('randomdorestmodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the ROC curve for different threshold values.\n",
    "# probability estimates of the positive class.\n",
    "y_scores_rf = rs_rf.predict_proba(features)[:, 1]\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(target, y_scores_rf)\n",
    "# Finding the AUC for the Random Forest classification model.\n",
    "rf_auc = auc(x=rf_fpr, y=rf_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_acc = rs_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area Under Curve: {}, Accuracy: {}'.format(rf_auc, rf_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = pd.DataFrame(rs_rf.predict(\n",
    "    test.drop(columns=['PassengerId'])), columns=['Survived'], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = pd.concat([test.PassengerId, y_pred_rf], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = BaggingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_params = {'n_estimators': [10, 100, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_bg = GridSearchCV(bg, param_grid=bg_params,\n",
    "                     scoring='accuracy', cv=kf, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_bg.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the ROC curve for different threshold values.\n",
    "# probability estimates of the positive class.\n",
    "y_scores_bg = gs_bg.predict_proba(features)[:, 1]\n",
    "bg_fpr, bg_tpr, bg_thresholds = roc_curve(target, y_scores_bg)\n",
    "# Finding the AUC for the Bagging classification model.\n",
    "bg_auc = auc(x=bg_fpr, y=bg_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_acc = gs_bg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area Under Curve: {}, Accuracy: {}'.format(bg_auc, bg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bg = pd.DataFrame(gs_bg.predict(\n",
    "    test.drop(columns=['PassengerId'])), columns=['Survived'], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_model = pd.concat([test.PassengerId, y_pred_bg], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_params = {'n_estimators': [100, 500, 1000,\n",
    "                               10000], 'learning_rate': [0.1, 0.5, 0.7, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ada = GridSearchCV(ada, param_grid=ada_params, cv=kf,\n",
    "                      scoring='accuracy', refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_ada.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gs_ada, 'adaboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ada = joblib.load('adaboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the ROC curve for different threshold values.\n",
    "# probability estimates of the positive class.\n",
    "y_scores_ada = gs_ada.predict_proba(features)[:, 1]\n",
    "ada_fpr, ada_tpr, ada_thresholds = roc_curve(target, y_scores_ada)\n",
    "# Finding the AUC for the AdaBoost classification model.\n",
    "ada_auc = auc(x=ada_fpr, y=ada_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_acc = gs_ada.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area Under Curve: {}, Accuracy: {}'.format(bg_auc, bg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = pd.DataFrame(gs_ada.predict(\n",
    "    test.drop(columns=['PassengerId'])), columns=['Survived'], dtype='int64')\n",
    "ada_model = pd.concat([test.PassengerId, y_pred_ada], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we want to tune our model to minimize the variance, which is sensitivity of the prediction score to the change in training set, so, we will use cross-validation. We will use the validation curve to help us choose the best validation fraction of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = ens.GradientBoostingClassifier()\n",
    "param_name = 'validation_fraction'\n",
    "param_range = np.arange(1, 5.5, 0.5)*1e-1\n",
    "train_score, test_score = validation_curve(\n",
    "    gboost, features, target, param_name, cv=10, param_range=param_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_score_mean = np.mean(train_score, axis= 1)\n",
    "test_score_mean = np.mean(test_score, axis= 1)\n",
    "\n",
    "# Plot validation fraction VS. cross-validated scores for training and Validation sets.\n",
    "plt.figure()\n",
    "plt.xlabel(\"Validation fraction\")\n",
    "plt.ylabel(\"Cross validated accuracy score\")\n",
    "plt.plot(np.arange(1,5.5, 0.5)*1e-1, train_score_mean, color = 'blue')\n",
    "plt.plot(np.arange(1,5.5, 0.5)*1e-1, test_score_mean, color = 'red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_test_diff = train_score_mean - test_score_mean\n",
    "\n",
    "# validation fraction VS. difference of cross-validated scores between train and Dev sets.\n",
    "plt.figure()\n",
    "plt.xlabel(\"Validation fraction\")\n",
    "plt.ylabel(\"Diff. Cross validated accuracy score\")\n",
    "plt.plot(np.arange(1,5.5, 0.5)*1e-1, train_test_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the minimum variance is at valdiation fraction = 0.45.<br/>\n",
    "We will choose validation fraction of 0.45."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection for Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation_fraction= 0.35,\n",
    "    n_iter_no_change= 150, tol= 0.001, random_state= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = ens.GradientBoostingClassifier(validation_fraction= 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.001, 0.01,0.1,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.VarianceThreshold(threshold= i)\n",
    "    selected_features = selector.fit_transform(features)\n",
    "    gboost.fit(selected_features, target)\n",
    "    y_pred = gboost.predict(selected_features)\n",
    "    scores.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "plt.plot([0.001, 0.01,0.1,0.5], np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy is obtained after execluding features whose variance is less than 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKbest method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = list(range(1,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_k = []\n",
    "for i in number_of_features:\n",
    "    selector = sklearn.feature_selection.SelectKBest(k=i)\n",
    "    selected_features = selector.fit_transform(features, target)\n",
    "    gboost.fit(selected_features, target)\n",
    "    y_pred = gboost.predict(selected_features)\n",
    "    scores_k.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "plt.plot(list(range(1,13)), scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features :\", np.argmax(np.array(scores_k)) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy score is obtained after selecting the best 11 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFECV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = sklearn.feature_selection.RFECV(gboost, step= 1, cv= 7)\n",
    "selector.fit(features, target)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % selector.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(selector.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFromModel method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.arange(1, 10, 0.1) *1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_sfm = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.SelectFromModel(gboost, threshold= i)\n",
    "    selector.fit(features, target)\n",
    "    selected_features = features.loc[:, selector.get_support()]\n",
    "    gboost.fit(selected_features, target)\n",
    "    y_pred = gboost.predict(selected_features)\n",
    "    scores_sfm.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Threshold Value\")\n",
    "plt.ylabel(\"Cross validation score\")    \n",
    "plt.plot(np.arange(1, 10, 0.1) *1e-2, scores_sfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum accuracy score is :\", np.max(np.array(scores_sfm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal threshold :\", threshold[np.argmax(np.array(scores_sfm))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that SelectFromModel method results in the highest accuracy score with threshold = 0.018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with best 15 features.\n",
    "selector = sklearn.feature_selection.SelectFromModel(gboost, threshold= 0.018)\n",
    "selected_features = selector.fit_transform(features, target)\n",
    "gboost.fit(selected_features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GB hyperparamters tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will use randomized search and we'll follow a coarse to fine strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_params = {'learning_rate': [0.1 , 0.2, 0.25 ], 'n_estimators': [\n",
    "    50, 100, 200], 'max_features': [None, 'log2', 'sqrt'],\n",
    "                'loss': ['deviance', 'exponential']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_gboost = RandomizedSearchCV(gboost, param_distributions= gboost_params,\n",
    "                         cv= 10, scoring='accuracy', refit=True, n_iter= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_gboost.fit(selected_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_gboost.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the ROC curve for different threshold values.\n",
    "# probability estimates of the positive class.\n",
    "y_scores_gboost = rs_gboost.predict_proba(selected_features)[:, 1]\n",
    "gboost_fpr, gboost_tpr, gboost_thresholds = sklearn.metrics.roc_curve(\n",
    "    target, y_scores_gboost)\n",
    "# Finding the AUC for the Gradient Boost classification model.\n",
    "gboost_auc = sklearn.metrics.auc(x=gboost_fpr, y=gboost_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_acc = rs_gboost.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area Under Curve: {}, Accuracy: {}'.format(gboost_auc, gboost_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gboost = pd.DataFrame(rs_gboost.predict(\n",
    "    test.loc[:,selector.get_support()]), columns=['Survived'], dtype='int64')\n",
    "gboost_model = pd.concat([passengerID, y_pred_gboost], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_model.to_csv('gboost.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.001, 0.01,0.1,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.VarianceThreshold(threshold= i)\n",
    "    selected_features = selector.fit_transform(features)\n",
    "    xgboost.fit(selected_features, target)\n",
    "    y_pred = xgboost.predict(selected_features)\n",
    "    scores.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "plt.plot([0.001, 0.01,0.1,0.5], np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy is obtained after execluding features whose variance is less than 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKbest method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = list(range(1,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_k = []\n",
    "for i in number_of_features:\n",
    "    selector = sklearn.feature_selection.SelectKBest(k=i)\n",
    "    selected_features = selector.fit_transform(features, target)\n",
    "    xgboost.fit(selected_features, target)\n",
    "    y_pred = xgboost.predict(selected_features)\n",
    "    scores_k.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "plt.plot(list(range(1,13)), scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features :\", np.argmax(np.array(scores_k)) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy score is obtained after selecting the best 11 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFECV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = sklearn.feature_selection.RFECV(xgboost, step= 1, cv= 7)\n",
    "selector.fit(features, target)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % selector.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(selector.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFromModel method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.arange(1, 10, 0.1) *1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_sfm = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.SelectFromModel(xgboost, threshold= i)\n",
    "    selector.fit(features, target)\n",
    "    selected_features = features.loc[:, selector.get_support()]\n",
    "    xgboost.fit(selected_features, target)\n",
    "    y_pred = xgboost.predict(selected_features)\n",
    "    scores_sfm.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Threshold Value\")\n",
    "plt.ylabel(\"Cross validation score\")    \n",
    "plt.plot(np.arange(1, 10, 0.1) *1e-2, scores_sfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum accuracy score is :\", np.max(np.array(scores_sfm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal threshold :\", threshold[np.argmax(np.array(scores_sfm))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that SelectKBest method results in the highest accuracy score with K = 12, which is the total number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.score(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgboost = pd.DataFrame(xgboost.predict(test), columns=['Survived'], dtype='int64')\n",
    "xgboost_model = pd.concat([passengerID, y_pred_xgboost], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model.to_csv('xgb.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection for LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgboost = lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.001, 0.01,0.1,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.VarianceThreshold(threshold= i)\n",
    "    selected_features = selector.fit_transform(features)\n",
    "    lgboost.fit(selected_features, target)\n",
    "    y_pred = lgboost.predict(selected_features)\n",
    "    scores.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "plt.plot([0.001, 0.01,0.1,0.5], np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy is obtained after execluding features whose variance is less than 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKbest method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = list(range(1,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_k = []\n",
    "for i in number_of_features:\n",
    "    selector = sklearn.feature_selection.SelectKBest(k=i)\n",
    "    selected_features = selector.fit_transform(features, target)\n",
    "    lgboost.fit(selected_features, target)\n",
    "    y_pred = lgboost.predict(selected_features)\n",
    "    scores_k.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "plt.plot(list(range(1,13)), scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features :\", np.argmax(np.array(scores_k)) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy score is obtained after selecting the best 11 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFECV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = sklearn.feature_selection.RFECV(lgboost, step= 1, cv= 7)\n",
    "selector.fit(features, target)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % selector.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(selector.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFromModel method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.001, 0.01, 0.05, 0.1 , 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_sfm = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.SelectFromModel(lgboost, threshold= i)\n",
    "    selector.fit(features, target)\n",
    "    selected_features = features.loc[:, selector.get_support()]\n",
    "    lgboost.fit(selected_features, target)\n",
    "    y_pred = lgboost.predict(selected_features)\n",
    "    scores_sfm.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Threshold Value\")\n",
    "plt.ylabel(\"Cross validation score\")    \n",
    "plt.plot([0.001, 0.01, 0.05, 0.1 , 0.5], scores_sfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum accuracy score is :\", np.max(np.array(scores_sfm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal threshold :\", threshold[np.argmax(np.array(scores_sfm))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that SelectKBest method results in the highest accuracy score with K = 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with the best 11 features selected.\n",
    "selector = sklearn.feature_selection.SelectKBest(k= 11)\n",
    "selected_features = selector.fit_transform(features, target)\n",
    "lgboost.fit(selected_features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgboost = pd.DataFrame(lgboost.predict(\n",
    "    test.loc[:,selector.get_support()]), columns=['Survived'], dtype='int64')\n",
    "lgboost_model = pd.concat([passengerID, y_pred_lgboost], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgboost_model.to_csv('lgboost.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection for LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctboost = ctb.CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.001, 0.01,0.1,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.VarianceThreshold(threshold= i)\n",
    "    selected_features = selector.fit_transform(features)\n",
    "    ctboost.fit(selected_features, target)\n",
    "    y_pred = ctboost.predict(selected_features)\n",
    "    scores.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "plt.plot([0.001, 0.01,0.1,0.5], np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy is obtained after execluding features whose variance is less than 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKbest method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = list(range(1,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_k = []\n",
    "for i in number_of_features:\n",
    "    selector = sklearn.feature_selection.SelectKBest(k=i)\n",
    "    selected_features = selector.fit_transform(features, target)\n",
    "    ctboost.fit(selected_features, target)\n",
    "    y_pred = ctboost.predict(selected_features)\n",
    "    scores_k.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "plt.plot(list(range(1,13)), scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features :\", np.argmax(np.array(scores_k)) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy score is obtained after selecting the best 12 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFECV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = sklearn.feature_selection.RFECV(ctboost, step= 1, cv= 7)\n",
    "selector.fit(features, target)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % selector.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(selector.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFromModel method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.001, 0.01, 0.05, 0.1 , 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_sfm = []\n",
    "for i in threshold:\n",
    "    selector = sklearn.feature_selection.SelectFromModel(lgboost, threshold= i)\n",
    "    selector.fit(features, target)\n",
    "    selected_features = features.loc[:, selector.get_support()]\n",
    "    lgboost.fit(selected_features, target)\n",
    "    y_pred = lgboost.predict(selected_features)\n",
    "    scores_sfm.append(sklearn.metrics.accuracy_score(target, y_pred))\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Threshold Value\")\n",
    "plt.ylabel(\"Cross validation score\")    \n",
    "plt.plot([0.001, 0.01, 0.05, 0.1 , 0.5], scores_sfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum accuracy score is :\", np.max(np.array(scores_sfm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal threshold :\", threshold[np.argmax(np.array(scores_sfm))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that SelectKBest method results in the highest accuracy score with K = 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctboost.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ctboost = pd.DataFrame(ctboost.predict(\n",
    "    test.drop(columns=['PassengerId'])), columns=['Survived'], dtype='int64')\n",
    "ctboost_model = pd.concat([test.PassengerId, y_pred_ctboost], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VotingClassifier(estimators=[\n",
    "    ('lr', lr), ('NB', gs_nb), ('KNN', gs_knn), ('SVM', rs_svm), ('DT', gs_dt),\n",
    "    ('RF', rs_rf), ('BG', gs_bg), ('AdaBoost', gs_ada), ('GBM', gs_gboost),\n",
    "    ('XGBM', gs_xgb), ('LightGBM', lgboost), ('CatBoost', ctboost)],\n",
    "    voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(v, 'votingclassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = joblib.load('votingclassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the ROC curve for different threshold values.\n",
    "# probability estimates of the positive class.\n",
    "y_scores_v = v.predict_proba(features)[:, 1]\n",
    "v_fpr, v_tpr, v_thresholds = roc_curve(target, y_scores_v)\n",
    "# Finding the AUC for the Voting classification model.\n",
    "v_auc = auc(x=v_fpr, y=v_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area Under Curve: {}'.format(v_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_v = pd.DataFrame(v.predict(test.drop(columns=['PassengerId'])), columns=[\n",
    "                        'Survived'], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_model = pd.concat([test.PassengerId, y_pred_v], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validate, y_train, y_validate = train_test_split(\n",
    "    features, target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionCV(cv=kf)\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=14, leaf_size=20, p=1, weights='uniform')\n",
    "svm = SVC(kernel='rbf', gamma=0.1, degree=1, C=500, shrinking=True)\n",
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate=0.5)\n",
    "adab = AdaBoostClassifier(n_estimators=500, learning_rate=0.7)\n",
    "bg = BaggingClassifier(n_estimators=100)\n",
    "gboost = GradientBoostingClassifier(\n",
    "    validation_fraction=0.1, n_iter_no_change=20, tol=0.005)\n",
    "xgboost = xgb.XGBClassifier()\n",
    "lgboost = lgb.LGBMClassifier()\n",
    "ctboost = ctb.CatBoostClassifier(iterations=200, learning_rate=0.1, depth=10)\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train, y_train)\n",
    "nb.fit(x_train, y_train)\n",
    "knn.fit(x_train, y_train)\n",
    "svm.fit(x_train, y_train)\n",
    "gb.fit(x_train, y_train)\n",
    "adab.fit(x_train, y_train)\n",
    "bg.fit(x_train, y_train)\n",
    "gboost.fit(x_train, y_train)\n",
    "xgboost.fit(x_train, y_train)\n",
    "lgboost.fit(x_train, y_train)\n",
    "ctboost.fit(x_train, y_train)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = lr.predict(x_validate)\n",
    "pred2 = nb.predict(x_validate)\n",
    "pred3 = knn.predict(x_validate)\n",
    "pred4 = svm.predict(x_validate)\n",
    "pred5 = gb.predict(x_validate)\n",
    "pred6 = adab.predict(x_validate)\n",
    "pred7 = bg.predict(x_validate)\n",
    "pred8 = gboost.predict(x_validate)\n",
    "pred9 = xgboost.predict(x_validate)\n",
    "pred10 = lgboost.predict(x_validate)\n",
    "pred11 = ctboost.predict(x_validate)\n",
    "pred12 = rf.predict(x_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred1 = lr.predict(test.drop(columns=['PassengerId']))\n",
    "test_pred2 = nb.predict(test.drop(columns=['PassengerId']))\n",
    "test_pred3 = knn.predict(test.drop(columns=['PassengerId']))\n",
    "test_pred4 = svm.predict(test.drop(columns=['PassengerId']))\n",
    "test_pred5 = gb.predict(test.drop(columns=['PassengerId']))\n",
    "test_pred6 = adab.predict(test.drop(columns=['PassengerId']))\n",
    "test_pred7 = bg.predict(test.drop(columns=['PassengerId']))\n",
    "test_pred8 = gboost.predict(test.drop(columns=['PassengerId']))\n",
    "test_pred9 = xgboost.predict(test.drop(columns=['PassengerId']))\n",
    "test_pred10 = lgboost.predict(test.drop(columns=['PassengerId']))\n",
    "test_pred11 = ctboost.predict(test.drop(columns=['PassengerId']))\n",
    "test_pred12 = rf.predict(test.drop(columns=['PassengerId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_predictions = np.column_stack((pred1, pred2, pred3, pred4, pred5, pred6, pred7,\n",
    "                                       pred8, pred9, pred10, pred11, pred12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_test_predictions = np.column_stack((test_pred1, test_pred2, test_pred3, test_pred4, test_pred5,\n",
    "                                            test_pred6, test_pred7, test_pred8, test_pred9, test_pred10,\n",
    "                                            test_pred11, test_pred12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta model\n",
    "meta_model = LogisticRegressionCV(cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_model.fit(stacked_predictions, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack = pd.DataFrame(meta_model.predict(\n",
    "    stacked_test_predictions), columns=['Survived'], dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model = pd.concat([test.PassengerId, y_pred_stack], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comaprison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([(lr_auc, lr_acc), (nb_auc, nb_acc), (knn_auc, knn_acc), (dt_auc, dt_acc),\n",
    "              (rf_auc, rf_acc), (svm_auc, svm_acc), (bg_auc, bg_acc), (ada_auc, ada_acc), (v_auc, 'NA')],\n",
    "             columns=['AUC', 'Accuracy'],\n",
    "             index=['Logistic Regression', 'Naive Bayes', 'KNN', 'Decision Tree',\n",
    "                    'Random Forest', 'SVM', 'Bagging', 'AdaBoost', 'Voting'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.plot(lr_fpr, lr_tpr, 'b', label='LR_AUC = %0.2f' % lr_auc)\n",
    "plt.plot(nb_fpr, nb_tpr, 'g', label='NB_AUC = %0.2f' % nb_auc)\n",
    "plt.plot(knn_fpr, knn_tpr, 'orange', label='KNN_AUC = %0.2f' % knn_auc)\n",
    "plt.plot(svm_fpr, svm_tpr, 'y', label='SVM_AUC = %0.2f' % svm_auc)\n",
    "plt.plot(dt_fpr, dt_tpr, 'brown', label='DT_AUC = %0.2f' % dt_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, 'grey', label='RF_AUC = %0.2f' % rf_auc)\n",
    "plt.plot(bg_fpr, bg_tpr, 'black', label='BG_AUC = %0.2f' % bg_auc)\n",
    "plt.plot(ada_fpr, ada_tpr, 'pink', label='Ada_AUC = %0.2f' % ada_auc)\n",
    "plt.plot(v_fpr, v_tpr, 'purple', label='Voting_AUC = %0.2f' % v_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 181.177546,
   "position": {
    "height": "202.76px",
    "left": "665.781px",
    "right": "20px",
    "top": "131.996px",
    "width": "328.24px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
